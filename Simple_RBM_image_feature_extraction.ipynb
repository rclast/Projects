{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a simple example of how to perform image feature extraction using RBM. The dataset is a compilation of images of famous individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import PIL.Image\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a main folder that has folders for each individual\n",
    "# Each individual's folder then has one or more jpg images\n",
    "\n",
    "directory = 'C:\\\\Users\\\\Ross Last\\\\Python files\\\\Unit 4 Unsupervised Learning\\\\Lesson 3 Neural Networks and Deep Learning\\\\lfw-dataset\\\\lfw-deepfunneled\\\\lfw-deepfunneled'\n",
    "\n",
    "images = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    for f in os.listdir(directory + '\\\\' + file):\n",
    "        if f.endswith(\".jpg\"):\n",
    "            images.append(directory + '\\\\' + file + '\\\\' + f)\n",
    "\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 250, 250, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For local machine memory issues, trim down to 100 images\n",
    "images = images[:100]\n",
    "\n",
    "images_list = []\n",
    "\n",
    "# Create three dimensional array of each image and append to empty list\n",
    "for im in images:\n",
    "    images_list.append(np.array(PIL.Image.open(im)))\n",
    "\n",
    "# Create four dimensional array out of the list\n",
    "images_array = np.array(images_list)\n",
    "\n",
    "images_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 187500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape into two dimensional dataframe for feeding into RBM\n",
    "# Multiply 250 x 250 x 3 to get 187500 for the second dimension\n",
    "images_df = np.reshape(images_array, newshape=(100, 187500))\n",
    "\n",
    "images_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=100, n_iter=20,\n",
       "       random_state=42, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete unneeded data for memory\n",
    "del images_array, images_list, images\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "rbm = BernoulliRBM(learning_rate=0.1, n_components=100, n_iter=20, random_state=42)\n",
    "\n",
    "rbm.fit(images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.15685724e+02,  3.17862114e+02,  3.00884539e+02, ...,\n",
       "         2.15635677e+02,  1.98824610e+02,  2.16248742e+02],\n",
       "       [ 3.10739797e+02,  3.12488933e+02,  2.94833208e+02, ...,\n",
       "         2.13661708e+02,  1.96901181e+02,  2.14046689e+02],\n",
       "       [-1.57947150e-02, -1.71220584e-02, -2.66870541e-03, ...,\n",
       "        -4.71051400e-05,  1.07506446e-03,  6.60296193e-03],\n",
       "       ...,\n",
       "       [ 3.15661222e+02,  3.17835422e+02,  3.00865360e+02, ...,\n",
       "         2.15618169e+02,  1.98850782e+02,  2.16229956e+02],\n",
       "       [ 3.13204648e+02,  3.14869085e+02,  2.97039599e+02, ...,\n",
       "         2.15048468e+02,  1.98233705e+02,  2.15306885e+02],\n",
       "       [ 3.10818217e+02,  3.12588000e+02,  2.94942891e+02, ...,\n",
       "         2.13778163e+02,  1.96945586e+02,  2.14268014e+02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the features extracted from RBM on the image data that could be fed into another model\n",
    "rbm.components_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
